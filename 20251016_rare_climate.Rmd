---
title: "20251016 work"
output: html_notebook
---

오늘의 목표: 추린 기후 변수로 기후공간 생성하기, 희귀 기후 확인하기, 희귀 기후에 사는 식물종 확인하기

우선 추려낸 6개 기후 변수로 기후공간을 생성하자.

~~clm_df_filtered가 추려낸 6개 기후 변수를 포함하는 마스킹된 데이터프레임이므로 그대로 사용한다.~~ 나중에 환경공간에서 출현 좌표를 추출할 때 X, Y 정보가 필요하므로 clm_var_filter에서 데이터프레임을 생성해서 진행한다.


```{r}
#PCA를 이용해 환경공간 생성하기

library(terra)
library(ggplot2)
library(dplyr)

# 그 안의 모든 셀 값을 데이터프레임으로 변환
clm_fil_xy <- as.data.frame(clm_var_filter, xy = TRUE, na.rm = TRUE)

# NA값이 있는 셀 확인
na_per_variable <- colSums(is.na(clm_fil_xy[, -c(1:2)]))
print(na_per_variable)

# NA 제거
clm_fil_xy_nona <- clm_fil_xy %>% filter(complete.cases(.))

# PCA 수행 (환경 변수만 선택)
clm_only <- clm_fil_xy_nona %>% dplyr::select(-x, -y)
clm_pca_result <- prcomp(clm_only, scale. = TRUE)

#saveRDS(pca_result, file = "pca_result_all.rds")

#pca_result <- readRDS("pca_result_all.rds")

clm_pca_df <- as.data.frame(clm_pca_result$x)


#png(filename = "./그림/pca_all_250929.png", width = 2400, height = 2000, res = 300)

# 6. 시각화: 환경공간에서 각 카테고리 색상 표시
ggplot(clm_pca_df, aes(x = PC1, y = PC2)) +
  geom_point(alpha = 0.4, size = 0.6) +
  labs(title = "대한민국의 기후공간 분포",
       x = "PC1", y = "PC2") +
  theme_minimal() 



```


꼬리가 긴 새 모양이 되었다. PCA의 설명력은 어느 정도일까? 60은 넘어야 하는데 말이지


```{r}
#PCA 설명력 확인하기

# PCA 결과에서 고유값 (eigenvalues)은 sdev^2
eigenvalues <- clm_pca_result$sdev^2

explained_variance <- eigenvalues / sum(eigenvalues)
cumulative_variance <- cumsum(explained_variance)

pc_var_df <- data.frame(
  PC = paste0("PC", 1:length(explained_variance)),
  Explained = explained_variance,
  Cumulative = cumulative_variance
)

print(pc_var_df)
#1축 설명력 47.2, 2축 설명력 19.1

# 1. PCA 결과에서 rotation 행렬 (각 PC의 loading)
loadings <- clm_pca_result$rotation  # 행: 변수 / 열: PC

# 2. loading^2 하면 각 PC에서의 기여 비율 (분산 비중)
loading_sq <- loadings^2

# 3. 각 PC에서의 상대적 기여율 (총합이 1이 되도록)
pc_contrib <- sweep(loading_sq, 2, colSums(loading_sq), FUN = "/")

# 4. 보기 쉽게 정리
pc_contrib_df <- as.data.frame(pc_contrib)
pc_contrib_df$Variable <- rownames(pc_contrib_df)
pc_contrib_df <- pc_contrib_df[, c("Variable", "PC1", "PC2", "PC3")]
print(pc_contrib_df)

#PCA 예쁘게 그리기####
library(factoextra)

#png(filename = "./그림/PCA_importance_all_250929.png", width = 1600, height = 1200, res = 300)

fviz_pca_var(
  clm_pca_result,
  col.var = "contrib",  # 기여도 기반 색상
  gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
  repel = TRUE,          # 텍스트 겹침 방지
  geom = c("arrow", "text"),  # 화살표와 텍스트 모두 출력
  arrowsize = 1.2,            # 화살표 두께 (기본은 0.5)
  labelsize = 4,              # 글씨 크기
  fontface = "bold"           # 글씨 두께 (bold)
)


```

npp의 상관성이 낮게 나왔으며, bio14와 15가 PC1축에서 0.2이상의 설명력을 나타내고 bio3과 gsp가 PC2축에서 0.3 이상의 설명력을 보였다.

이제 기후공간의 빈도를 확인해보자

```{r}
library(dplyr)
library(ggplot2)
library(terra)
library(scales)

# PCA 좌표 가져오기
clm_pca_df <- as.data.frame(clm_pca_result$x)

# 셀 면적 (m²)
clm_cell_area_m2 <- prod(res(clm_var_filter))

# PCA 공간을 격자로 나눠 빈도 계산
pca_bins <- clm_pca_df %>%
  mutate(
    PC1_bin = cut(PC1, breaks = 50),  # bin 개수 조정 가능
    PC2_bin = cut(PC2, breaks = 50)
  ) %>%
  group_by(PC1_bin, PC2_bin) %>%
  summarise(cell_count = n(), .groups = "drop") %>%
  mutate(
    area = cell_count * clm_cell_area_m2,
    area_km2 = area / 1e6,  # km² 변환
    # 빈도(cell_count)를 기준으로 10등분 (quantile 사용)
    # ntile(변수, 등분 수) 함수 사용
    count_decile = as.factor(ntile(cell_count, 10)) 
  )

# 사용할 10가지 색상 벡터 생성
# RColorBrewer Blues 9가지 색상 + 가장 진한 파랑 수동 추가
custom_blues_10 <- c(RColorBrewer::brewer.pal(9, "Blues"), "#000033")

# 시각화 (빈도 10등분, 범주형 색상 사용)
ggplot(pca_bins, aes(x = PC1_bin, y = PC2_bin, fill = count_decile)) +
  geom_tile() +
  scale_fill_manual(
    # 빈도수가 많은(10) 곳에 진한 색상이 오도록 순서를 역전시킵니다.
    values = rev(custom_blues_10), 
    labels = c("하위 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "상위 10%"),
    na.translate = FALSE # 결측치(빈 셀)는 표시하지 않음
  ) +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.ticks = element_blank()
  ) +
  labs(x = "PC1", y = "PC2", fill = "빈도 10분위")
```

이제 각 출현자료들이 얼마나 희귀한 기후에 출현하는지 확인해보자
일단 출현자료부터 추리자자

```{r}
library(terra)
library(dplyr)

rast_merged_5179 <- rast("./data/large_landcover_5179.tif")

# 종 발생 데이터 로드
occurrence <- read.csv("./data/occurrence241_250916.csv", header = TRUE)
occurrence <- occurrence[,3:6]

# 좌표 변환 및 셀 ID 추출
occurrence_vect <- vect(occurrence, geom = c("decimalLongitude", "decimalLatitude"), crs = "EPSG:4326")
occurrence_vect_5179 <- project(occurrence_vect, "EPSG:5179")

xy_coords <- crds(occurrence_vect_5179)
cell_ids <- cellFromXY(clm_var_filter, xy_coords)
clm_occ_df <- cbind(occurrence, cell = cell_ids)

# 종별 + 셀별로 중복 제거 (random 1개 유지)
set.seed(42)  # 재현 가능하게
clm_thinned_occ <- clm_occ_df %>%
  group_by(국명, cell) %>%
  slice_sample(n = 1) %>%
  ungroup()
#thinning 결과 4871->3087로 줄어듬..

# 환경 변수 추출
thinned_vect <- vect(clm_thinned_occ, geom = c("decimalLongitude", "decimalLatitude"), crs = "EPSG:4326")
thinned_vect_5179 <- project(thinned_vect, "EPSG:5179")

occ_env <- terra::extract(clm_var_filter, thinned_vect_5179)

thinned_with_env <- cbind(clm_thinned_occ, occ_env[,-1])  # 첫번째(ID) 제외

# =======================================================
# 핵심 수정: EPSG:5179 좌표 (X, Y)를 데이터프레임에 추가
# =======================================================

# 1. thinned_vect_f_5179 객체에서 5179 좌표를 추출합니다.
coords_5179 <- crds(thinned_vect_5179)
colnames(coords_5179) <- c("X_5179", "Y_5179")

# 2. thinned_with_env 데이터프레임에 5179 좌표를 추가합니다.
thinned_with_env <- cbind(thinned_with_env, coords_5179)

# 6. 마스킹 필터링 준비
thinned_vect_f <- vect(thinned_with_env, geom = c("decimalLongitude", "decimalLatitude"), crs = "EPSG:4326")
thinned_vect_f_5179 <- project(thinned_vect_f, "EPSG:5179")

# 래스터에서 값이 1인 위치만 TRUE로 표시 (mask 생성)
rast_mask <- rast_merged_5179 == 1

# 7. 마스크 값 추출 및 필터링
mask_values <- terra::extract(rast_mask, thinned_vect_f_5179)

# 마스크 값이 1이 아니거나 (마스크 바깥) NA인 경우의 인덱스 찾기
idx <- which(mask_values[,2] != 1 | is.na(mask_values[,2]))

# 마스크 바깥에 있는 데이터만 추출하여 thinned_outside_mask에 할당
thinned_outside_mask <- thinned_with_env[idx, ]

# 결과 확인
# 3087 -> 2956 (데이터의 변화는 기존과 동일하게 유지됩니다.)
 unique(thinned_outside_mask$국명) # 241 taxa

# 8. 결과 저장 (X_5179, Y_5179 포함)
# 저장된 CSV 파일에는 decimalLongitude, decimalLatitude 외에 X_5179, Y_5179 열이 추가됩니다.

#write.csv(thinned_outside_mask, "./data/thinned_occur_clm_5179_251016.csv", row.names = FALSE)

```

토양에는 na 값이 있는데 기후는 na값이 없어서 출현수가 더 많아졌다.
그래서 일단 줄어든 2956개의 출현자료를 바탕으로 확인한다.

```{r}

library(dplyr)
library(terra) # names(clm_var_filter)를 위해 필요

# =======================================================
# 환경 변수 PCA 변환 및 10분위 정보 매칭 (수정됨)
# =======================================================

# 1. PCA 투영에 필요한 환경 변수 데이터 준비
env_vars <- names(clm_var_filter)
thinned_env_data_for_pca <- thinned_outside_mask %>%
  select(all_of(env_vars))

# NA가 포함된 행의 인덱스를 저장 (NA 처리 후 원본 데이터 매칭을 위해 사용)
# 환경 변수에 결측치가 없다고 했으므로, 이 단계는 사실상 전체 행을 처리합니다.
rows_to_keep <- which(apply(is.na(thinned_env_data_for_pca), 1, any) == FALSE)
thinned_env_data_no_na <- na.omit(thinned_env_data_for_pca)


# 2. PCA 변환 적용 및 좌표 조정 (Capping)

# 2.1. PCA 변환 적용
# clm_pca_result는 전체 기후 데이터로 학습된 PCA 모델 객체입니다.
thinned_pca_coords <- predict(clm_pca_result, newdata = thinned_env_data_no_na)
thinned_pca_df <- as.data.frame(thinned_pca_coords)


# 2.2. 격자 구간(bin) 계산을 위한 경계 정의
# clm_pca_result$x에서 PC1, PC2의 범위를 가져옵니다.
# pc1_breaks와 pc2_breaks의 길이는 51이어야 합니다 (50개 빈).
pc1_breaks <- seq(min(clm_pca_result$x[, 1]), max(clm_pca_result$x[, 1]), length.out = 51)
pc2_breaks <- seq(min(clm_pca_result$x[, 2]), max(clm_pca_result$x[, 2]), length.out = 51)

# **NA 문제 해결을 위해 경계 확장 (미세한 아웃라이어 처리)**
# 이전에 1e-10을 더했지만, 확실하게 하기 위해 더 명확하게 Capping을 적용합니다.

# 2.3. PCA 좌표 강제 조정 (Capping)
# 출현지 좌표가 전체 기후 데이터의 경계를 벗어나면 경계값으로 조정 (NA 방지)
thinned_pca_df_capped <- thinned_pca_df %>%
  mutate(
    # PC1이 전체 기후 공간의 Min/Max를 벗어나면 Min/Max 값으로 조정
    PC1 = pmax(min(pc1_breaks), pmin(max(pc1_breaks), PC1)),
    # PC2가 전체 기후 공간의 Min/Max를 벗어나면 Min/Max 값으로 조정
    PC2 = pmax(min(pc2_breaks), pmin(max(pc2_breaks), PC2))
  )

# 2.4. PCA 공간 격자 구간(bin)으로 변환
thinned_pca_binned <- thinned_pca_df_capped %>%
  mutate(
    # cut() 함수에 Capped된 좌표 사용
    PC1_bin = as.character(cut(PC1, breaks = pc1_breaks, include.lowest = TRUE, ordered_result = TRUE)),
    PC2_bin = as.character(cut(PC2, breaks = pc2_breaks, include.lowest = TRUE, ordered_result = TRUE))
  )


# 3. 빈도 등분위 정보 매칭 (조인)
# 3.1. pca_bins에서 PC1_bin, PC2_bin, count_decile 열만 선택하고 문자열로 변환
pca_bin_info <- pca_bins %>%
  select(PC1_bin, PC2_bin, count_decile) %>%
  mutate(
    PC1_bin = as.character(PC1_bin), # 조인 키 유형 일치
    PC2_bin = as.character(PC2_bin)  # 조인 키 유형 일치
  ) %>%
  distinct() # 중복 행 제거

# 3.2. thinned_pca_binned 데이터와 빈도 정보 조인
thinned_with_decile <- thinned_pca_binned %>%
  left_join(pca_bin_info, by = c("PC1_bin", "PC2_bin"))

# 4. 원래의 thinned_outside_mask 데이터에 등분위 정보 최종 추가

# 4.1. Capping된 PC 좌표를 thinned_with_decile에 추가
thinned_with_decile <- thinned_with_decile %>%
  mutate(
    PC1_original = thinned_pca_df$PC1, # 조정 전 원래 PC 좌표
    PC2_original = thinned_pca_df$PC2 # 조정 전 원래 PC 좌표
  )

# 4.2. 원본 데이터에 조인하여 최종 데이터프레임 생성
# (rows_to_keep 인덱스를 사용하여 NA가 없는 행만 대상으로 처리합니다)
thinned_outside_mask_final <- thinned_outside_mask[rows_to_keep, ] %>%
  mutate(
    PC1 = thinned_with_decile$PC1_original,
    PC2 = thinned_with_decile$PC2_original,
    PC1_bin = thinned_with_decile$PC1_bin,
    PC2_bin = thinned_with_decile$PC2_bin,
    count_decile = thinned_with_decile$count_decile
  )

# 5. 결과 확인
# Capping으로 인해 NA는 0개가 되었는지 확인
cat("\n[Capping 후 빈도 10분위별 출현지 개수]\n")
print(table(thinned_outside_mask_final$count_decile, useNA = "ifany"))
```
왜 NA가 나오는지 모르겠다. 일단 1일수록 희귀한 기후이다

```{r}
# =======================================================
# Step 1: pca_bins에 연속적인 Bin 중앙 좌표 (PC_center) 추가
# (Bin 레이블 문자열을 파싱하여 중앙값을 계산)
# =======================================================

library(stringr)

pca_bins <- pca_bins %>%
  # PC1_bin의 경계값 파싱 및 중앙값 계산
  mutate(
    # 문자열에서 숫자 부분만 추출 (예: "(1.2, 3.4]" -> "1.2", "3.4")
    PC1_bounds = str_extract_all(PC1_bin, "-?[0-9.]+")
  ) %>%
  rowwise() %>%
  mutate(
    PC1_start = as.numeric(PC1_bounds[1]),
    PC1_end = as.numeric(PC1_bounds[2]),
    PC1_center = (PC1_start + PC1_end) / 2
  ) %>%
  ungroup() %>%
  # PC2_bin에 대해서도 동일하게 계산
  mutate(
    PC2_bounds = str_extract_all(PC2_bin, "-?[0-9.]+")
  ) %>%
  rowwise() %>%
  mutate(
    PC2_start = as.numeric(PC2_bounds[1]),
    PC2_end = as.numeric(PC2_bounds[2]),
    PC2_center = (PC2_start + PC2_end) / 2
  ) %>%
  ungroup() %>%
  # PC_bounds 리스트 열만 제거하고, start/end/center 열은 유지
  select(-PC1_bounds, -PC2_bounds)


# =======================================================
# Step 2: 시각화: PCA 공간의 기후 빈도 10분위 및 종 출현 지점 오버레이
# (geom_tile에 연속적인 PC_center 좌표 사용)
# =======================================================

# ggplot을 사용하여 시각화
ggplot(pca_bins, aes(x = PC1_center, y = PC2_center, fill = count_decile)) + # X, Y에 center 좌표 사용
  geom_tile(aes(width = PC1_end - PC1_start, height = PC2_end - PC2_start)) + # 타일의 너비/높이를 빈 크기에 맞춤
  scale_fill_manual(
    values = rev(custom_blues_10), # 10은 높은 빈도, 1은 낮은 빈도에 매핑
    labels = c("하위 10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "상위 10%"),
    name = "기후 빈도 10분위",
    na.value = "grey80" # pca_bins에 혹시 모를 NA가 있다면 회색으로 표시
  ) +
  # thinned_outside_mask_final의 출현 지점 오버레이
  # inherit.aes = FALSE를 사용하여 geom_tile의 aes 설정을 상속받지 않도록 합니다.
  geom_point(data = thinned_outside_mask_final, 
             aes(x = PC1, y = PC2, color = is.na(count_decile)), # X, Y에 원래 PC 좌표 사용
             inherit.aes = FALSE, 
             size = 1.5, 
             alpha = 0.8,
             shape = 16) + # 원형 점
  coord_fixed(ratio = 1) + # PC1과 PC2 축의 비율을 1:1로 고정하여 왜곡 방지
  scale_color_manual(
    values = c("FALSE" = "black", "TRUE" = "red"), # NA가 아니면 검정색, NA이면 빨간색
    labels = c("TRUE" = "분류되지 않음 (NA)", "FALSE" = "분류됨"),
    name = "출현지 분류 여부"
  ) +
  theme_minimal() +
  theme(
    # 축 텍스트를 제거하지 않고, PC1, PC2의 연속적인 값을 표시하도록 변경
    axis.text = element_text(size = 8), 
    axis.ticks = element_line(),
    panel.grid = element_blank() # 격자선 제거
  ) +
  labs(x = "PC1", y = "PC2", 
       title = "PCA 공간의 기후 빈도 10분위 및 종 출현 지점") +
  guides(fill = guide_legend(order = 1), # 빈도 10분위 범례를 먼저 표시
         color = guide_legend(order = 2)) # 출현지 분류 여부 범례를 나중에 표시
```

일단 오늘은 여기까지 하자.. 내일 논문 스터디 준비도 하고 제안서 수정도 해야 된다..